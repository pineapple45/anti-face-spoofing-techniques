{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50bb010c",
      "metadata": {
        "id": "50bb010c"
      },
      "source": [
        "# DATA PROCESSING AND CLEANUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2870e3e6",
      "metadata": {
        "id": "2870e3e6"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef24280",
      "metadata": {
        "id": "8ef24280"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30497953",
      "metadata": {
        "id": "30497953"
      },
      "outputs": [],
      "source": [
        "import os,tarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f09d77",
      "metadata": {
        "id": "a1f09d77"
      },
      "outputs": [],
      "source": [
        "# change current working directory to OULU\n",
        "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14f385b",
      "metadata": {
        "id": "a14f385b"
      },
      "outputs": [],
      "source": [
        "# list all files in OULU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e9b2edc",
      "metadata": {
        "id": "7e9b2edc"
      },
      "outputs": [],
      "source": [
        "# EXTRACT .tar FILES FOR TRAINING DATA\n",
        "train_files = tarfile.open('replayattack-train.tar.gz')\n",
        "train_files.extractall('train_files') # specify which folder to extract to\n",
        "train_files.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faa5c8b1",
      "metadata": {
        "id": "faa5c8b1"
      },
      "outputs": [],
      "source": [
        "# EXTRACT .tar FILES FOR TESTING DATA\n",
        "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
        "test_files = tarfile.open('replayattack-test.tar.gz')\n",
        "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
        "test_files.extractall('test_files') # specify which folder to extract to\n",
        "test_files.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ddf2838",
      "metadata": {
        "id": "7ddf2838"
      },
      "outputs": [],
      "source": [
        "# EXTRACT .tar FILES FOR ENROLLMENT DATA\n",
        "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
        "enrollment_files = tarfile.open('replayattack-enroll.tar.gz')\n",
        "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
        "enrollment_files.extractall('enrollment_files') # specify which folder to extract to\n",
        "enrollment_files.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3443a561",
      "metadata": {
        "id": "3443a561"
      },
      "outputs": [],
      "source": [
        "# EXTRACT .tar FILES FOR DEVLOPEMENT DATA\n",
        "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
        "dev_files = tarfile.open('replayattack-devel.tar.gz')\n",
        "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
        "dev_files.extractall('dev_files') # specify which folder to extract to\n",
        "dev_files.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08f6ed2",
      "metadata": {
        "id": "d08f6ed2"
      },
      "outputs": [],
      "source": [
        "# EXTRACT .tar FILES FOR FACE LOCATIONS DATA\n",
        "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
        "face_loc_files = tarfile.open('replayattack-face-locations-v2.tar.gz')\n",
        "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
        "face_loc_files.extractall('face_loc_files') # specify which folder to extract to\n",
        "face_loc_files.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa113a6d",
      "metadata": {
        "id": "fa113a6d"
      },
      "outputs": [],
      "source": [
        "# EXTRACT .tar FILES FOR PROTOCOLS DATA\n",
        "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
        "protocols_files = tarfile.open('protocols-v3.tar.gz')\n",
        "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
        "protocols_files.extractall('protocols_files') # specify which folder to extract to\n",
        "protocols_files.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca306e5",
      "metadata": {
        "id": "cca306e5"
      },
      "outputs": [],
      "source": [
        "# EXTRACT .tar FILES FOR COMPETETIONS ICB 2013 TESTSET DATA\n",
        "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
        "icb_test_files = tarfile.open('competition_icb2013_testset.tar.gz')\n",
        "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
        "icb_test_files.extractall('icb_test_files') # specify which folder to extract to\n",
        "icb_test_files.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c486d873",
      "metadata": {
        "id": "c486d873"
      },
      "source": [
        "### EXTRACTING FRAMES FROM INPUT VIDEO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a1c2880",
      "metadata": {
        "id": "1a1c2880"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4b96c77",
      "metadata": {
        "id": "b4b96c77"
      },
      "outputs": [],
      "source": [
        "# DEFINING PARAMETERS FOR VIDEO CLASSIFICATION\n",
        "IMG_SIZE=256\n",
        "CHANNELS=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b255734",
      "metadata": {
        "id": "3b255734"
      },
      "outputs": [],
      "source": [
        "# The following two methods are taken from this tutorial:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d721f68",
      "metadata": {
        "id": "0d721f68"
      },
      "outputs": [],
      "source": [
        "import cv2  \n",
        "  \n",
        "# Load the cascade  \n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  \n",
        "  \n",
        "# To capture video from existing video.   \n",
        "cap = cv2.VideoCapture('test.mov')  \n",
        "  \n",
        "while True:  \n",
        "    # Read the frame  \n",
        "    _, img = cap.read()  \n",
        "  \n",
        "    # Convert to grayscale  \n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
        "  \n",
        "    # Detect the faces  \n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)  \n",
        "  \n",
        "    # Draw the rectangle around each face  \n",
        "    for (x, y, w, h) in faces:  \n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)  \n",
        "  \n",
        "    # Display  \n",
        "    cv2.imshow('Video', img)  \n",
        "  \n",
        "    # Stop if escape key is pressed  \n",
        "    k = cv2.waitKey(30) & 0xff  \n",
        "    if k==27:  \n",
        "        break  \n",
        "          \n",
        "# Release the VideoCapture object  \n",
        "cap.release()  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93da835",
      "metadata": {
        "id": "b93da835"
      },
      "source": [
        "# ACTUAL COMPUTATION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CODE CELL IN GOOGLE-COLLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DBO5qiA4H-Gx",
        "outputId": "f9798f22-b115-4d06-e043-fb9d56eeff3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DBO5qiA4H-Gx",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CODE CELL IN GOOGLE-COLLAB\n",
        "%cd '/content/drive/MyDrive/BTP/replay-attack-processed'"
      ],
      "metadata": {
        "id": "TNc-3Ky0IAyP",
        "outputId": "1fcd48ea-3375-4021-b2ef-b295ca8b6100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TNc-3Ky0IAyP",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BTP/replay-attack-processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1f0460d2",
      "metadata": {
        "id": "1f0460d2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import zipfile, os, cv2, random\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import load_model,Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from PIL import Image\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import requests\n",
        "import base64\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from io import BytesIO\n",
        "matplotlib.rcParams['figure.figsize'] = (12,12)\n",
        "matplotlib.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "71a6ca81",
      "metadata": {
        "id": "71a6ca81",
        "outputId": "0bb29141-710b-4f00-f980-035340c9d401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59afb695",
      "metadata": {
        "id": "59afb695"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CODE CELL IN GOOGLE-COLLAB\n",
        "# IMG_SHAPE = (256, 256, 3)\n",
        "archive = zipfile.ZipFile('/content/drive/MyDrive/BTP/replay-attack-processed/train.zip', 'r')\n",
        "image_paths = [k for k in list(archive.namelist()) if '.jpg' in k]\n",
        "print('Train: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))\n",
        "\n",
        "archive = zipfile.ZipFile('/content/drive/MyDrive/BTP/replay-attack-processed/val.zip', 'r')\n",
        "image_paths = [k for k in list(archive.namelist()) if '.jpg' in k]\n",
        "print('Val: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))\n",
        "\n",
        "archive = zipfile.ZipFile('/content/drive/MyDrive/BTP/replay-attack-processed/test.zip', 'r')\n",
        "image_paths = [k for k in list(archive.namelist()) if '.jpg' in k]\n",
        "print('Test: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))"
      ],
      "metadata": {
        "id": "S7XTzy6iIG6H",
        "outputId": "4297301e-4684-4755-c03b-a9ba935e36d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S7XTzy6iIG6H",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Total = 91705 , Attack = 69215 , Real = 22490\n",
            "Val: Total = 90952 , Attack = 68467 , Real = 22485\n",
            "Test: Total = 121028 , Attack = 91799 , Real = 29229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f585a7d8",
      "metadata": {
        "id": "f585a7d8",
        "outputId": "bd10af21-6714-4d09-a517-df2e6e9ee410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: Total = 91705 , Attack = 69215 , Real = 22490\n",
            "Test: Total = 121028 , Attack = 91799 , Real = 29229\n",
            "Validation: Total = 90952 , Attack = 68467 , Real = 22485\n"
          ]
        }
      ],
      "source": [
        "# RUN THIS CODE CELL LOCALLY\n",
        "# IMG_SHAPE = (256, 256, 3)\n",
        "image_paths = [k for k in glob.iglob('./data/train' + '/**/*.jpg', recursive=True)]\n",
        "print('Train: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))\n",
        "\n",
        "image_paths = [k for k in glob.iglob('./data/test' + '/**/*.jpg', recursive=True)]\n",
        "print('Test: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))\n",
        "\n",
        "image_paths = [k for k in glob.iglob('./data/val' + '/**/*.jpg', recursive=True)]\n",
        "print('Validation: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a1e96311",
      "metadata": {
        "id": "a1e96311"
      },
      "outputs": [],
      "source": [
        "def new_py_function(func, inp, Tout, name=None):\n",
        "  def wrapped_func(*flat_inp):\n",
        "    reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,expand_composites=True)\n",
        "    out = func(*reconstructed_inp)\n",
        "    return tf.nest.flatten(out, expand_composites=True)\n",
        "  flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\n",
        "  flat_out = tf.py_function(\n",
        "      func=wrapped_func, \n",
        "      inp=tf.nest.flatten(inp, expand_composites=True),\n",
        "      Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\n",
        "      name=name)\n",
        "  spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, \n",
        "                                   expand_composites=True)\n",
        "  out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\n",
        "  return out\n",
        "\n",
        "def _dtype_to_tensor_spec(v):\n",
        "  return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\n",
        "\n",
        "def _tensor_spec_to_dtype(v):\n",
        "  return v.dtype if isinstance(v, tf.TensorSpec) else v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f39a1eea",
      "metadata": {
        "id": "f39a1eea"
      },
      "outputs": [],
      "source": [
        "# RUN THIS CODE CELL LOCALLY\n",
        "class DataLoader:\n",
        "  def __init__(self, dataset_path, batch_size=4, image_size=(256, 256), shuffle=True):\n",
        "    self.images_paths = [k for k in glob.iglob(dataset_path + '/**/*.jpg', recursive=True)]\n",
        "    random.shuffle(self.images_paths)\n",
        "    self.length = len(self.images_paths)\n",
        "    self.dim = image_size\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(self.images_paths).map(\n",
        "            self.pad_map_fn, num_parallel_calls=3\n",
        "          )\n",
        "    if shuffle:\n",
        "#       dataset = dataset.shuffle(buffer_size=100000, reshuffle_each_iteration=True)\n",
        "      dataset = dataset.shuffle(buffer_size=5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(buffer_size=3)\n",
        "    # dataset = dataset.repeat()\n",
        "    self.dataset = dataset.apply(tf.data.experimental.ignore_errors())  \n",
        "                  \n",
        "  def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "  def load_tf_image(self, image_path):\n",
        "    image_path = image_path.numpy().decode(\"utf-8\")\n",
        "#     img_data = self.archive.read(image_path.strip())\n",
        "#     img_data = Image.open(image_path)\n",
        "#     img_data = img_data.tobytes(\"xbm\", \"rgb\")\n",
        "#     image = np.frombuffer(img_data, np.uint8)\n",
        "    image = cv2.imread(f\"{image_path}\")\n",
        "#     image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, self.dim)\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "    image = tf.image.per_image_standardization(image)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    # label - attack = 0, real = 1\n",
        "    if 'attack' in image_path:\n",
        "      label =  tf.constant([0])\n",
        "      label_8 = tf.zeros_like(tf.random.uniform(shape=(8,8,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_4 = tf.zeros_like(tf.random.uniform(shape=(4,4,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_2 = tf.zeros_like(tf.random.uniform(shape=(2,2,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_1 = tf.zeros_like(tf.random.uniform(shape=(1,1,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "    if 'real' in image_path:\n",
        "      label = tf.constant([1])\n",
        "      label_8 = tf.ones_like(tf.random.uniform(shape=(8,8,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_4 = tf.ones_like(tf.random.uniform(shape=(4,4,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_2 = tf.ones_like(tf.random.uniform(shape=(2,2,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_1 = tf.ones_like(tf.random.uniform(shape=(1,1,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "\n",
        "    return {'image': image, 'label': label, 'label_8': label_8, 'label_4': label_4, 'label_2': label_2, 'label_1': label_1}\n",
        "\n",
        "  def pad_map_fn(self, img_path):\n",
        "    return new_py_function(self.load_tf_image, inp=[img_path], Tout=({\"image\": tf.float32, \"label\": tf.int32, 'label_8': tf.float32, 'label_4': tf.float32, 'label_2': tf.float32, 'label_1': tf.float32}))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CODE CELL IN GOOGLE-COLLAB\n",
        "class DataLoader:\n",
        "  def __init__(self, dataset_path, batch_size=4, image_size=(256, 256), shuffle=True):\n",
        "    self.archive = zipfile.ZipFile(dataset_path, 'r')\n",
        "    self.images_paths = [k for k in list(self.archive.namelist()) if '.jpg' in k]\n",
        "    random.shuffle(self.images_paths)\n",
        "    self.length = len(self.images_paths)\n",
        "    self.dim = image_size\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(self.images_paths).map(\n",
        "            self.pad_map_fn, num_parallel_calls=3\n",
        "          )\n",
        "    if shuffle:\n",
        "      dtaset = dataset.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(buffer_size=3)\n",
        "    # dataset = dataset.repeat()\n",
        "    self.dataset = dataset.apply(tf.data.experimental.ignore_errors())  \n",
        "                  \n",
        "  def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "  def load_tf_image(self, image_path):\n",
        "    image_path = image_path.numpy().decode(\"utf-8\")\n",
        "    img_data = self.archive.read(image_path.strip())\n",
        "    image = np.frombuffer(img_data, np.uint8)\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, self.dim)\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "    image = tf.image.per_image_standardization(image)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    # label - spoof = 0, real = 1\n",
        "    if 'attack' in image_path:\n",
        "      label =  tf.constant([0])\n",
        "      label_8 = tf.zeros_like(tf.random.uniform(shape=(8,8,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_4 = tf.zeros_like(tf.random.uniform(shape=(4,4,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_2 = tf.zeros_like(tf.random.uniform(shape=(2,2,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_1 = tf.zeros_like(tf.random.uniform(shape=(1,1,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "    if 'real' in image_path:\n",
        "      label = tf.constant([1])\n",
        "      label_8 = tf.ones_like(tf.random.uniform(shape=(8,8,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_4 = tf.ones_like(tf.random.uniform(shape=(4,4,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_2 = tf.ones_like(tf.random.uniform(shape=(2,2,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "      label_1 = tf.ones_like(tf.random.uniform(shape=(1,1,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
        "\n",
        "    return {'image': image, 'label': label, 'label_8': label_8, 'label_4': label_4, 'label_2': label_2, 'label_1': label_1}\n",
        "\n",
        "  def pad_map_fn(self, img_path):\n",
        "    return new_py_function(self.load_tf_image, inp=[img_path], Tout=({\"image\": tf.float32, \"label\": tf.int32, 'label_8': tf.float32, 'label_4': tf.float32, 'label_2': tf.float32, 'label_1': tf.float32}))"
      ],
      "metadata": {
        "id": "48-3ImrZIly_"
      },
      "id": "48-3ImrZIly_",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1529577",
      "metadata": {
        "id": "c1529577",
        "outputId": "9d65872f-d140-4e6d-c84a-8008c6fd52b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-10 20:33:53.066962: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-04-10 20:33:53.067846: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        }
      ],
      "source": [
        "# RUN THIS CODE CELL LOCALLY\n",
        "loader = DataLoader('./data/train', batch_size=32,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CODE CELL IN GOOGLE-COLLAB\n",
        "loader = DataLoader('/content/drive/MyDrive/BTP/replay-attack-processed/train.zip', batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "2gu5nBMnI3hp"
      },
      "id": "2gu5nBMnI3hp",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8325141f",
      "metadata": {
        "id": "8325141f"
      },
      "outputs": [],
      "source": [
        "# loader.load_tf_image('./data/train/real/frame_15.jpg')['label_1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "574f9aaf",
      "metadata": {
        "id": "574f9aaf"
      },
      "outputs": [],
      "source": [
        "# loader.pad_map_fn('./data/train/real/frame_15.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d57a6d",
      "metadata": {
        "id": "c1d57a6d"
      },
      "outputs": [],
      "source": [
        "dataset = loader.dataset.take(2)\n",
        "# list(dataset.as_numpy_iterator())\n",
        "a = list(dataset.as_numpy_iterator())\n",
        "for a in list(dataset.as_numpy_iterator()):\n",
        "  print(a['image'].shape, a['label'].shape, a['label_8'].shape, a['label_4'].shape, a['label_2'].shape, a['label_1'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bef25f02",
      "metadata": {
        "id": "bef25f02"
      },
      "outputs": [],
      "source": [
        "IMG_SHAPE = (256, 256, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "aac0f000",
      "metadata": {
        "id": "aac0f000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adbaee4-695f-4133-865a-edb72b7413d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " resnet50 (Functional)          (None, 8, 8, 2048)   23587712    ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 8, 8, 2048)  0           ['resnet50[0][0]']               \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 4, 4, 2048)  0           ['resnet50[0][0]']               \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 2, 2, 2048)  0           ['resnet50[0][0]']               \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 1, 1, 2048)  0           ['resnet50[0][0]']               \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 8, 8, 1)      2049        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 4, 4, 1)      2049        ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 2, 2, 1)      2049        ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 1, 1, 1)      2049        ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 64)           0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 16)           0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 4)            0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 1)            0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 85)           0           ['flatten[0][0]',                \n",
            "                                                                  'flatten_1[0][0]',              \n",
            "                                                                  'flatten_2[0][0]',              \n",
            "                                                                  'flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 8, 8, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4, 4, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2, 2, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 1, 1, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            86          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,994\n",
            "Trainable params: 23,542,874\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "class RevisitResNet50(tf.keras.Model):\n",
        "  def __init__(self, name=\"revisit_resnet50\", **kwargs):\n",
        "    super(RevisitResNet50, self).__init__()\n",
        "    self.backbone = ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "    # avg. pooling\n",
        "    self.avgpool_8 = layers.AveragePooling2D(pool_size=(1,1), strides=1, padding='valid', data_format=None)\n",
        "    self.avgpool_4= layers.AveragePooling2D(pool_size=(2,2), strides=2, padding='valid', data_format=None)\n",
        "    self.avgpool_2= layers.AveragePooling2D(pool_size=(4,4), strides=4, padding='valid', data_format=None)\n",
        "    self.avgpool_1= layers.AveragePooling2D(pool_size=(8,8), strides=8, padding='valid', data_format=None)\n",
        "    # 1x1 conv\n",
        "    self.theta_8 = layers.Conv2D(1, (1,1), activation='sigmoid')\n",
        "    self.theta_4 = layers.Conv2D(1, (1,1), activation='sigmoid')\n",
        "    self.theta_2 = layers.Conv2D(1, (1,1), activation='sigmoid')\n",
        "    self.theta_1 = layers.Conv2D(1, (1,1), activation='sigmoid')\n",
        "    # dense layer\n",
        "    self.fc = layers.Dense(1, activation='sigmoid')\n",
        "    # loss\n",
        "    self.loss_object = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "  def call(self, input_img, label_8, label_4, label_2, label_1):\n",
        "    F = self.backbone(input_img)\n",
        "    # M8\n",
        "    x = self.avgpool_8(F)\n",
        "    M8 = self.theta_8(x)\n",
        "    # M4\n",
        "    x = self.avgpool_4(F)\n",
        "    M4 = self.theta_4(x)\n",
        "    # M2\n",
        "    x = self.avgpool_2(F)\n",
        "    M2 = self.theta_2(x)\n",
        "    # M1\n",
        "    x = self.avgpool_1(F)\n",
        "    M1 = self.theta_1(x)\n",
        "    # concatenate and predict\n",
        "    x = layers.Concatenate(axis=1)([layers.Flatten()(M8), layers.Flatten()(M4), layers.Flatten()(M2), layers.Flatten()(M1)])\n",
        "    y_pred = self.fc(x)\n",
        "    # pyramid loss\n",
        "    pyramid_loss = tf.reduce_mean([self.loss_object(label_8, M8), self.loss_object(label_4, M4), self.loss_object(label_2, M2), self.loss_object(label_1, M1)])\n",
        "    self.add_loss(pyramid_loss)\n",
        "\n",
        "    return y_pred\n",
        "  \n",
        "  def build_model(self):\n",
        "    x = layers.Input(shape=IMG_SHAPE)\n",
        "    label_8 = layers.Input(shape=(8,8,1), dtype=\"float32\")\n",
        "    label_4 = layers.Input(shape=(4,4,1), dtype=\"float32\")\n",
        "    label_2 = layers.Input(shape=(2,2,1), dtype=\"float32\")\n",
        "    label_1 = layers.Input(shape=(1,1,1), dtype=\"float32\")\n",
        "    return Model(inputs=[x, label_8, label_4, label_2, label_1], outputs=self.call(x, label_8, label_4, label_2, label_1))\n",
        "\n",
        "\n",
        "revisit_model = RevisitResNet50()\n",
        "test_model = revisit_model.build_model()\n",
        "test_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_apcer(y_true, y_pred):\n",
        "    true_spoof = 0  #### Spoof being 1\n",
        "    false_real = 0  #### real being 0\n",
        "    for i in range(len(y_true)):\n",
        "        target = y_true[i]\n",
        "        pred = y_pred[i]\n",
        "        if target:\n",
        "            true_spoof += 1\n",
        "            if not pred:\n",
        "                false_real += 1\n",
        "    return false_real / true_spoof if true_spoof else 0"
      ],
      "metadata": {
        "id": "nnOSZdeu_4PB"
      },
      "id": "nnOSZdeu_4PB",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_bpcer(y_true, y_pred):\n",
        "    true_real = 0  #### Spoof being 1\n",
        "    false_spoof = 0  #### real being 0\n",
        "    for i in range(len(y_true)):   \n",
        "        target = y_true[i]\n",
        "        pred = y_pred[i]\n",
        "        if not target:\n",
        "            true_real += 1\n",
        "            if pred:\n",
        "                false_spoof += 1\n",
        "    return false_spoof / true_real if true_real else 0"
      ],
      "metadata": {
        "id": "QSjzGrht_4Rs"
      },
      "id": "QSjzGrht_4Rs",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader('/content/drive/MyDrive/BTP/replay-attack-processed/train.zip', batch_size=64, shuffle=True)\n",
        "val_loader =  DataLoader('/content/drive/MyDrive/BTP/replay-attack-processed/val.zip', batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "L5wr9m4G_4UU"
      },
      "id": "L5wr9m4G_4UU",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train_loader.dataset)\n",
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2GlE7uc_4W9",
        "outputId": "fdd7999e-8380-4b77-d838-74a2febc60ff"
      },
      "id": "R2GlE7uc_4W9",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91705"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, decay=5e-5)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9, decay=5e-5)\n",
        "bce_loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "loss_metric = tf.keras.metrics.Mean()"
      ],
      "metadata": {
        "id": "4_e7so06_4aA"
      },
      "id": "4_e7so06_4aA",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "revisit_model.load_weights('/content/drive/MyDrive/BTP/replay-attack-processed/checkpoints/resnet50/cp.ckpt')"
      ],
      "metadata": {
        "id": "pdPg40wx_4cq"
      },
      "id": "pdPg40wx_4cq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 80\n",
        "start = datetime.now() \n",
        "for epoch in range(0,epochs+1): \n",
        "  print(\"Start of epoch %d\" % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset\n",
        "  for step, batch_train in enumerate(train_loader.dataset):\n",
        "    # print(batch_train['image'].shape, batch_train['label'].shape, batch_train['label_8'].shape, batch_train['label_4'].shape, batch_train['label_2'].shape, batch_train['label_1'].shape)\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = revisit_model(batch_train['image'], batch_train['label_8'], batch_train['label_4'], batch_train['label_2'], batch_train['label_1'], training=True)\n",
        "        # compute bcse loss\n",
        "        loss = bce_loss_fn(batch_train['label'], pred)\n",
        "        loss += sum(revisit_model.losses)  # add pyramid loss\n",
        "\n",
        "    grads = tape.gradient(loss, revisit_model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, revisit_model.trainable_weights))\n",
        "\n",
        "    loss_metric(loss)\n",
        "\n",
        "    if (step+1) % 750 == 0:\n",
        "      diff_time = datetime.now()-start\n",
        "      days, seconds = diff_time.days, diff_time.seconds\n",
        "      hours = days * 24 + seconds // 3600\n",
        "      minutes = (seconds % 3600) // 60\n",
        "      seconds = seconds % 60\n",
        "      print(\"step %d: mean loss = %.6f, time = %d:%d:%d\" % (step+1, loss_metric.result(), hours, minutes, seconds))\n",
        "      revisit_model.save_weights('/content/drive/MyDrive/BTP/replay-attack-processed/checkpoints/resnet50/cp.ckpt')\n",
        "\n",
        "revisit_model.save_weights('/content/drive/MyDrive/BTP/replay-attack-processed/checkpoints/resnet50/cp.ckpt')"
      ],
      "metadata": {
        "id": "cvjW3DQV_4hN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f642d5f8-c7af-4a8a-f221-ec3bdde2266a"
      },
      "id": "cvjW3DQV_4hN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of epoch 0\n",
            "step 750: mean loss = 0.246263, time = 0:12:44\n",
            "Start of epoch 1\n",
            "step 750: mean loss = 0.132357, time = 0:35:26\n",
            "Start of epoch 2\n",
            "step 750: mean loss = 0.099830, time = 0:58:21\n",
            "Start of epoch 3\n",
            "step 750: mean loss = 0.083328, time = 1:20:32\n",
            "Start of epoch 4\n",
            "step 750: mean loss = 0.072835, time = 1:43:3\n",
            "Start of epoch 5\n",
            "step 750: mean loss = 0.065554, time = 2:5:48\n",
            "Start of epoch 6\n",
            "step 750: mean loss = 0.060130, time = 2:28:6\n",
            "Start of epoch 7\n",
            "step 750: mean loss = 0.055899, time = 2:50:24\n",
            "Start of epoch 8\n",
            "step 750: mean loss = 0.052477, time = 3:12:42\n",
            "Start of epoch 9\n",
            "step 750: mean loss = 0.049640, time = 3:35:5\n",
            "Start of epoch 10\n",
            "step 750: mean loss = 0.047250, time = 3:57:21\n",
            "Start of epoch 11\n",
            "step 750: mean loss = 0.045190, time = 4:19:37\n",
            "Start of epoch 12\n",
            "step 750: mean loss = 0.043380, time = 4:42:8\n",
            "Start of epoch 13\n",
            "step 750: mean loss = 0.041795, time = 5:4:31\n",
            "Start of epoch 14\n",
            "step 750: mean loss = 0.040386, time = 5:26:55\n",
            "Start of epoch 15\n",
            "step 750: mean loss = 0.039120, time = 5:49:35\n",
            "Start of epoch 16\n",
            "step 750: mean loss = 0.037986, time = 6:12:7\n",
            "Start of epoch 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ths = 0.12\n",
        "for step, batch in enumerate(val_loader.dataset):\n",
        "  pred = revisit_model(batch['image'], batch['label_8'], batch['label_4'], batch['label_2'], batch['label_1'], training=False)\n",
        "  pred_ = [1 if i>ths else 0 for i in pred.numpy().reshape(batch['label'].shape[0])]\n",
        "  labels = [int(i) for i in batch['label'].numpy().reshape(batch['label'].shape[0])]\n",
        "  print(pred.numpy().reshape(batch['label'].shape[0]))\n",
        "  print(pred_)\n",
        "  print(labels)\n",
        "  print(calculate_apcer(labels, pred_))\n",
        "  break"
      ],
      "metadata": {
        "id": "hBll_DdM_4j8"
      },
      "id": "hBll_DdM_4j8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EhDA7MT7_4nT"
      },
      "id": "EhDA7MT7_4nT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UVKrK3tZ_4pk"
      },
      "id": "UVKrK3tZ_4pk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kHal8Qms_4sS"
      },
      "id": "kHal8Qms_4sS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JoeouS7k_4vI"
      },
      "id": "JoeouS7k_4vI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2W7EyQgF_4yM"
      },
      "id": "2W7EyQgF_4yM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "adglHyFA_41E"
      },
      "id": "adglHyFA_41E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5877d7e9",
      "metadata": {
        "id": "5877d7e9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Pixel Wise Supervision - REPLAY.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}