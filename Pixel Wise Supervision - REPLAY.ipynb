{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bb010c",
   "metadata": {},
   "source": [
    "# DATA PROCESSING AND CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2870e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef24280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30497953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f09d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change current working directory to OULU\n",
    "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all files in OULU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT .tar FILES FOR TRAINING DATA\n",
    "train_files = tarfile.open('replayattack-train.tar.gz')\n",
    "train_files.extractall('train_files') # specify which folder to extract to\n",
    "train_files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT .tar FILES FOR TESTING DATA\n",
    "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
    "test_files = tarfile.open('replayattack-test.tar.gz')\n",
    "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
    "test_files.extractall('test_files') # specify which folder to extract to\n",
    "test_files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf2838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT .tar FILES FOR ENROLLMENT DATA\n",
    "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
    "enrollment_files = tarfile.open('replayattack-enroll.tar.gz')\n",
    "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
    "enrollment_files.extractall('enrollment_files') # specify which folder to extract to\n",
    "enrollment_files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT .tar FILES FOR DEVLOPEMENT DATA\n",
    "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
    "dev_files = tarfile.open('replayattack-devel.tar.gz')\n",
    "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
    "dev_files.extractall('dev_files') # specify which folder to extract to\n",
    "dev_files.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT .tar FILES FOR FACE LOCATIONS DATA\n",
    "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
    "face_loc_files = tarfile.open('replayattack-face-locations-v2.tar.gz')\n",
    "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
    "face_loc_files.extractall('face_loc_files') # specify which folder to extract to\n",
    "face_loc_files.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa113a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT .tar FILES FOR PROTOCOLS DATA\n",
    "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
    "protocols_files = tarfile.open('protocols-v3.tar.gz')\n",
    "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
    "protocols_files.extractall('protocols_files') # specify which folder to extract to\n",
    "protocols_files.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca306e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT .tar FILES FOR COMPETETIONS ICB 2013 TESTSET DATA\n",
    "os.chdir('/media/pineapple45/Elements/anmol/btp/replayattack')\n",
    "icb_test_files = tarfile.open('competition_icb2013_testset.tar.gz')\n",
    "os.chdir('/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/replayattack')\n",
    "icb_test_files.extractall('icb_test_files') # specify which folder to extract to\n",
    "icb_test_files.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486d873",
   "metadata": {},
   "source": [
    "### EXTRACTING FRAMES FROM INPUT VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b96c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING PARAMETERS FOR VIDEO CLASSIFICATION\n",
    "IMG_SIZE=256\n",
    "CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b255734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following two methods are taken from this tutorial:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d721f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "  \n",
    "# Load the cascade  \n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  \n",
    "  \n",
    "# To capture video from existing video.   \n",
    "cap = cv2.VideoCapture('test.mov')  \n",
    "  \n",
    "while True:  \n",
    "    # Read the frame  \n",
    "    _, img = cap.read()  \n",
    "  \n",
    "    # Convert to grayscale  \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "    # Detect the faces  \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)  \n",
    "  \n",
    "    # Draw the rectangle around each face  \n",
    "    for (x, y, w, h) in faces:  \n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)  \n",
    "  \n",
    "    # Display  \n",
    "    cv2.imshow('Video', img)  \n",
    "  \n",
    "    # Stop if escape key is pressed  \n",
    "    k = cv2.waitKey(30) & 0xff  \n",
    "    if k==27:  \n",
    "        break  \n",
    "          \n",
    "# Release the VideoCapture object  \n",
    "cap.release()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d72789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89d955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b93da835",
   "metadata": {},
   "source": [
    "# ACTUAL COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0460d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile, os, cv2, random\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import load_model,Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import requests\n",
    "import base64\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "matplotlib.rcParams['figure.figsize'] = (12,12)\n",
    "matplotlib.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a6ca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59afb695",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f585a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Total = 91705 , Attack = 69215 , Real = 22490\n",
      "Test: Total = 121028 , Attack = 91799 , Real = 29229\n",
      "Validation: Total = 90952 , Attack = 68467 , Real = 22485\n"
     ]
    }
   ],
   "source": [
    "# IMG_SHAPE = (256, 256, 3)\n",
    "image_paths = [k for k in glob.iglob('./data/train' + '/**/*.jpg', recursive=True)]\n",
    "print('Train: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))\n",
    "\n",
    "image_paths = [k for k in glob.iglob('./data/test' + '/**/*.jpg', recursive=True)]\n",
    "print('Test: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))\n",
    "\n",
    "image_paths = [k for k in glob.iglob('./data/val' + '/**/*.jpg', recursive=True)]\n",
    "print('Validation: Total =',len(image_paths), ', Attack =',len([path for path in image_paths if 'attack' in path]), ', Real =', len([path for path in image_paths if 'real' in path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e96311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_py_function(func, inp, Tout, name=None):\n",
    "  def wrapped_func(*flat_inp):\n",
    "    reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,expand_composites=True)\n",
    "    out = func(*reconstructed_inp)\n",
    "    return tf.nest.flatten(out, expand_composites=True)\n",
    "  flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\n",
    "  flat_out = tf.py_function(\n",
    "      func=wrapped_func, \n",
    "      inp=tf.nest.flatten(inp, expand_composites=True),\n",
    "      Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\n",
    "      name=name)\n",
    "  spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, \n",
    "                                   expand_composites=True)\n",
    "  out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\n",
    "  return out\n",
    "\n",
    "def _dtype_to_tensor_spec(v):\n",
    "  return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\n",
    "\n",
    "def _tensor_spec_to_dtype(v):\n",
    "  return v.dtype if isinstance(v, tf.TensorSpec) else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39a1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "  def __init__(self, dataset_path, batch_size=4, image_size=(256, 256), shuffle=True):\n",
    "    self.images_paths = [k for k in glob.iglob(dataset_path + '/**/*.jpg', recursive=True)]\n",
    "    random.shuffle(self.images_paths)\n",
    "    self.length = len(self.images_paths)\n",
    "    self.dim = image_size\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(self.images_paths).map(\n",
    "            self.pad_map_fn, num_parallel_calls=3\n",
    "          )\n",
    "    if shuffle:\n",
    "#       dataset = dataset.shuffle(buffer_size=100000, reshuffle_each_iteration=True)\n",
    "      dataset = dataset.shuffle(buffer_size=5000, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(buffer_size=3)\n",
    "    # dataset = dataset.repeat()\n",
    "    self.dataset = dataset.apply(tf.data.experimental.ignore_errors())  \n",
    "                  \n",
    "  def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "  def load_tf_image(self, image_path):\n",
    "    image_path = image_path.numpy().decode(\"utf-8\")\n",
    "#     img_data = self.archive.read(image_path.strip())\n",
    "#     img_data = Image.open(image_path)\n",
    "#     img_data = img_data.tobytes(\"xbm\", \"rgb\")\n",
    "#     image = np.frombuffer(img_data, np.uint8)\n",
    "    image = cv2.imread(f\"{image_path}\")\n",
    "#     image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, self.dim)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # label - attack = 0, real = 1\n",
    "    if 'attack' in image_path:\n",
    "      label =  tf.constant([0])\n",
    "      label_8 = tf.zeros_like(tf.random.uniform(shape=(8,8,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
    "      label_4 = tf.zeros_like(tf.random.uniform(shape=(4,4,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
    "      label_2 = tf.zeros_like(tf.random.uniform(shape=(2,2,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
    "      label_1 = tf.zeros_like(tf.random.uniform(shape=(1,1,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
    "    if 'real' in image_path:\n",
    "      label = tf.constant([1])\n",
    "      label_8 = tf.ones_like(tf.random.uniform(shape=(8,8,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
    "      label_4 = tf.ones_like(tf.random.uniform(shape=(4,4,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
    "      label_2 = tf.ones_like(tf.random.uniform(shape=(2,2,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
    "      label_1 = tf.ones_like(tf.random.uniform(shape=(1,1,1), minval=0, maxval=1, dtype=tf.dtypes.float32))\n",
    "\n",
    "    return {'image': image, 'label': label, 'label_8': label_8, 'label_4': label_4, 'label_2': label_2, 'label_1': label_1}\n",
    "\n",
    "  def pad_map_fn(self, img_path):\n",
    "    return new_py_function(self.load_tf_image, inp=[img_path], Tout=({\"image\": tf.float32, \"label\": tf.int32, 'label_8': tf.float32, 'label_4': tf.float32, 'label_2': tf.float32, 'label_1': tf.float32}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1529577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 20:33:53.066962: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-10 20:33:53.067846: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader('./data/train', batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader.load_tf_image('./data/train/real/frame_15.jpg')['label_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader.pad_map_fn('./data/train/real/frame_15.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d57a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 20:34:08.038337: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3) (32, 1) (32, 8, 8, 1) (32, 4, 4, 1) (32, 2, 2, 1) (32, 1, 1, 1)\n",
      "(32, 256, 256, 3) (32, 1) (32, 8, 8, 1) (32, 4, 4, 1) (32, 2, 2, 1) (32, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = loader.dataset.take(2)\n",
    "# list(dataset.as_numpy_iterator())\n",
    "a = list(dataset.as_numpy_iterator())\n",
    "for a in list(dataset.as_numpy_iterator()):\n",
    "  print(a['image'].shape, a['label'].shape, a['label_8'].shape, a['label_4'].shape, a['label_2'].shape, a['label_1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef25f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0f000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877d7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pixel-wise-super]",
   "language": "python",
   "name": "conda-env-pixel-wise-super-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
