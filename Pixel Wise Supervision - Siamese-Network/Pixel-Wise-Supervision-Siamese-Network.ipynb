{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIXEL-WISE-SUPERVISION-SIAMESE-NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /content/drive/My\\ Drive/Siamese\\ Network/dataset.7z ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00006)\n",
    "binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# base_dir = \".\"\n",
    "base_dir = \"/content/drive/My Drive/Siamese Network\"\n",
    "\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.join(base_dir, 'logs/func/%s' % stamp)\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "scalar_logdir = os.path.join(base_dir, 'logs/scalars/%s' % stamp)\n",
    "file_writer = tf.summary.create_file_writer(scalar_logdir + \"/metrics\")\n",
    "\n",
    "checkpoint_path = os.path.join(base_dir, 'logs/model/siamese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code cell is taken from the source code of keras_vggface.\n",
    "I tried using the preprocess_input function provided by tf.keras but they provide different results.\n",
    "To my knowledge, it seems that the mean values which are subtracted in each image are different.\n",
    "'''\n",
    "K = tf.keras.backend\n",
    "\n",
    "def preprocess_input(x, data_format=None, version=1):\n",
    "    x_temp = np.copy(x)\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    assert data_format in {'channels_last', 'channels_first'}\n",
    "\n",
    "    if version == 1:\n",
    "        if data_format == 'channels_first':\n",
    "            x_temp = x_temp[:, ::-1, ...]\n",
    "            x_temp[:, 0, :, :] -= 93.5940\n",
    "            x_temp[:, 1, :, :] -= 104.7624\n",
    "            x_temp[:, 2, :, :] -= 129.1863\n",
    "        else:\n",
    "            x_temp = x_temp[..., ::-1]\n",
    "            x_temp[..., 0] -= 93.5940\n",
    "            x_temp[..., 1] -= 104.7624\n",
    "            x_temp[..., 2] -= 129.1863\n",
    "\n",
    "    elif version == 2:\n",
    "        if data_format == 'channels_first':\n",
    "            x_temp = x_temp[:, ::-1, ...]\n",
    "            x_temp[:, 0, :, :] -= 91.4953\n",
    "            x_temp[:, 1, :, :] -= 103.8827\n",
    "            x_temp[:, 2, :, :] -= 131.0912\n",
    "        else:\n",
    "            x_temp = x_temp[..., ::-1]\n",
    "            x_temp[..., 0] -= 91.4953\n",
    "            x_temp[..., 1] -= 103.8827\n",
    "            x_temp[..., 2] -= 131.0912\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return x_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset_path, batch_size=32, shuffle=True):\n",
    "        self.dataset = self.curate_dataset(dataset_path)\n",
    "        self.dataset_path = dataset_path\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size =batch_size\n",
    "        self.no_of_people = len(list(self.dataset.keys()))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        people = list(self.dataset.keys())[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        P = []\n",
    "        A = []\n",
    "        N = []\n",
    "        \n",
    "        for person in people:\n",
    "            anchor_index = random.randint(0, len(self.dataset[person])-1)\n",
    "            a = self.get_image(person, anchor_index)\n",
    "            \n",
    "            positive_index = random.randint(0, len(self.dataset[person])-1)\n",
    "            while positive_index == anchor_index:\n",
    "                positive_index = random.randint(0, len(self.dataset[person])-1)\n",
    "            p = self.get_image(person, positive_index)\n",
    "            \n",
    "            negative_person_index = random.randint(0, self.no_of_people - 1)\n",
    "            negative_person = list(self.dataset.keys())[negative_person_index]\n",
    "            while negative_person == person:\n",
    "                negative_person_index = random.randint(0, self.no_of_people - 1)\n",
    "                negative_person = list(self.dataset.keys())[negative_person_index]\n",
    "            \n",
    "            negative_index = random.randint(0, len(self.dataset[negative_person])-1)\n",
    "            n = self.get_image(negative_person, negative_index)\n",
    "            P.append(p)\n",
    "            A.append(a)\n",
    "            N.append(n)\n",
    "        A = np.asarray(A)\n",
    "        N = np.asarray(N)\n",
    "        P = np.asarray(P)\n",
    "        return [A, P, N]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.no_of_people // self.batch_size\n",
    "        \n",
    "    def curate_dataset(self, dataset_path):\n",
    "        with open(os.path.join(dataset_path, 'list.txt'), 'r') as f:\n",
    "            dataset = {}\n",
    "            image_list = f.read().split()\n",
    "            print('Total images: ',len(image_list))\n",
    "            for image in image_list:\n",
    "                folder_name, file_name = image.split('/')\n",
    "                if folder_name in dataset.keys():\n",
    "                    dataset[folder_name].append(file_name)\n",
    "                else:\n",
    "                    dataset[folder_name] = [file_name]\n",
    "        return dataset\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            keys = list(self.dataset.keys())\n",
    "            random.shuffle(keys)\n",
    "            dataset_ =  {}\n",
    "            for key in keys:\n",
    "                dataset_[key] = self.dataset[key]\n",
    "            self.dataset = dataset_\n",
    "            \n",
    "    def get_image(self, person, index):\n",
    "        # print(os.path.join(self.dataset_path, os.path.join('images/' + person, self.dataset[person][index])))\n",
    "        img = cv2.imread(os.path.join(self.dataset_path, os.path.join('images/' + person, self.dataset[person][index])))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = np.asarray(img, dtype=np.float64)\n",
    "        img = preprocess_input(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 4\n",
    "# cv2.imshow(\"Positive\", p[index])\n",
    "# cv2.imshow(\"Negative\", n[index])\n",
    "# cv2.imshow(\"Anchor\", a[index])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggface = tf.keras.models.Sequential()\n",
    "vggface.add(tf.keras.layers.Convolution2D(64, (3, 3), activation='relu', padding=\"SAME\", input_shape=(224,224, 3)))\n",
    "vggface.add(tf.keras.layers.Convolution2D(64, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "vggface.add(tf.keras.layers.Convolution2D(128, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.Convolution2D(128, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "vggface.add(tf.keras.layers.Convolution2D(256, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.Convolution2D(256, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.Convolution2D(256, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n",
    "vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "vggface.add(tf.keras.layers.Flatten())\n",
    "\n",
    "vggface.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "vggface.add(tf.keras.layers.Dropout(0.5))\n",
    "vggface.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "vggface.add(tf.keras.layers.Dropout(0.5))\n",
    "vggface.add(tf.keras.layers.Dense(2622, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggface.load_weights(os.path.join(base_dir, 'vgg_face_weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggface.pop()\n",
    "vggface.add(tf.keras.layers.Dense(128, use_bias=False))\n",
    "\n",
    "for layer in vggface.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(tf.keras.Model):\n",
    "    def __init__(self, vgg_face):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.vgg_face = vgg_face\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        image_1, image_2, image_3 =  inputs\n",
    "        with tf.name_scope(\"Anchor\") as scope:\n",
    "            feature_1 = self.vgg_face(image_1)\n",
    "            feature_1 = tf.math.l2_normalize(feature_1, axis=-1)\n",
    "        with tf.name_scope(\"Positive\") as scope:\n",
    "            feature_2 = self.vgg_face(image_2)\n",
    "            feature_2 = tf.math.l2_normalize(feature_2, axis=-1)\n",
    "        with tf.name_scope(\"Negative\") as scope:\n",
    "            feature_3 = self.vgg_face(image_3)\n",
    "            feature_3 = tf.math.l2_normalize(feature_3, axis=-1)\n",
    "        return [feature_1, feature_2, feature_3]\n",
    "    \n",
    "    @tf.function\n",
    "    def get_features(self, inputs):\n",
    "        return tf.math.l2_normalize(self.vgg_face(inputs), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNetwork(vggface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, alpha = 0.2):\n",
    "    # Triplet Loss function.\n",
    "    anchor,positive,negative = x\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.mean(K.maximum(basic_loss,0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = loss_function(y_pred)\n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.trace_on(graph=True, profiler=False)\n",
    "output = model([tf.zeros((32,224,224,3)), tf.zeros((32,224,224,3)), tf.zeros((32,224,224,3))])\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name=\"my_func_trace\", step=0, profiler_outdir=logdir)\n",
    "    \n",
    "tf.summary.trace_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(dataset_path='./dataset/')\n",
    "print(data_generator[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_curated = data_generator.curate_dataset(dataset_path='./dataset/')\n",
    "print(len(data_curated['n000009']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, p, n = data_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# cv2.imshow(\"Positive\", p[index])\n",
    "# cv2.imshow(\"Negative\", n[index])\n",
    "# cv2.imshow(\"Anchor\", a[index])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/drive/My\\ Drive/Siamese\\ Network/logs/\n",
    "# %tensorboard --logdir ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracy = []\n",
    "\n",
    "no_of_batches = data_generator.__len__()\n",
    "for i in range(1, epochs+1, 1):\n",
    "    loss = 0\n",
    "    with tqdm(total=no_of_batches) as pbar:\n",
    "        \n",
    "        description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n",
    "        pbar.set_description_str(description)\n",
    "        \n",
    "        for j in range(no_of_batches):\n",
    "            data = data_generator[j]\n",
    "            temp = train(data)\n",
    "            loss += temp\n",
    "            \n",
    "            pbar.update()\n",
    "            print_statement = \"Loss :\" + str(temp.numpy())\n",
    "            pbar.set_postfix_str(print_statement)\n",
    "        \n",
    "        loss /= no_of_batches\n",
    "        losses.append(loss.numpy())\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('Loss', data=loss.numpy(), step=i)\n",
    "            \n",
    "        print_statement = \"Loss :\" + str(loss.numpy())\n",
    "        \n",
    "        pbar.set_postfix_str(print_statement)\n",
    "\n",
    "checkpoint.save(checkpoint_path)\n",
    "print(\"Checkpoint Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pixel-wise-super]",
   "language": "python",
   "name": "conda-env-pixel-wise-super-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
