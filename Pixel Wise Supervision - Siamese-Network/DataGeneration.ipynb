{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA GENERATION FOR PIXEL-WISE-SUPERVISION SIAMESE NETWORK REPLAY-ATTACK DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERT VIDEO DATA TO FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/Revisiting-Pixel-Wise-Supervision-for-Face-Anti-Spoofing/Pixel Wise Supervision - Siamese-Network'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataGeneration.ipynb                              \u001b[0m\u001b[01;34mreplay-dummy-person-wise\u001b[0m/\r\n",
      " \u001b[01;34mdataset\u001b[0m/                                          \u001b[01;34mreplay-images\u001b[0m/\r\n",
      " haarcascade_frontalface_default.xml               \u001b[01;35mtest_img.png\u001b[0m\r\n",
      "'PIxel Wise Supervision - Siamese-Network.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from imutils import face_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(img):\n",
    "    # Convert to grayscale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "    # Detect the faces  \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 4)  \n",
    "    \n",
    "    # Draw rectangle around the faces and crop the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        faces = img[y:y + h, x:x + w]\n",
    "        \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_face('./test_img.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START CAPTURING VIDEOS\n",
    "\n",
    "def extract_multiple_videos(intput_filenames,pathOut,img_class,frame_rate, resize):\n",
    "    \"\"\"Extract video files into sequence of images.\n",
    "       Intput_filenames is a list for video file names\"\"\"\n",
    "\n",
    "    i = 0  # Counter of first video\n",
    "\n",
    "    # Iterate file names:\n",
    "    for intput_filename in intput_filenames:\n",
    "        random_str_count = 7\n",
    "        img_name = 'client'\n",
    "        pattern = intput_filename.split('/')\n",
    "        for p in pattern:\n",
    "            if 'client' in p:\n",
    "                f_name = p.split('_')\n",
    "                for name in f_name:\n",
    "                    if name.find('client') != -1:\n",
    "                        img_name = name\n",
    "        \n",
    "        # print('the image will be named as:', img_name)\n",
    "        \n",
    "        \n",
    "        sec_count = 0\n",
    "        cap = cv2.VideoCapture(intput_filename)\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC,(sec_count*frame_rate))\n",
    "\n",
    "        # Keep iterating break\n",
    "        while True:\n",
    "#             rand_str = str(''.join(random.choices(string.ascii_uppercase +\n",
    "#                              string.digits, k = random_str_count)))\n",
    "            ret, frame = cap.read()  # Read frame from first video\n",
    "\n",
    "            if ret:\n",
    "                try:\n",
    "                    cropped_faces = extract_face(frame)\n",
    "                    cropped_faces = cv2.resize(cropped_faces,(resize,resize))\n",
    "                    write_path = pathOut + f'{img_name}_{i}_{img_class}.png'\n",
    "                    cv2.imwrite(write_path, cropped_faces)  # Write frame to JPEG file (1.jpg, 2.jpg, ...)\n",
    "                    i += 1 # Advance file counter\n",
    "                    sec_count += 1\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                # Break the interal loop when res status is False.\n",
    "                break\n",
    "\n",
    "            # cv2.waitKey(100) #Wait 100msec (for debugging)\n",
    "\n",
    "        cap.release() #Release must be inside the outer loop\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(in_dir , out_dir,img_class,frame_rate=500,resize=256):\n",
    "    # traverse whole directory\n",
    "    dir_list = []\n",
    "    for root, dirs, files in os.walk(f'{in_dir}'):\n",
    "        # select file name\n",
    "        for file in files:\n",
    "            # check the extension of files\n",
    "            if file.endswith('.mov'):\n",
    "                # print whole path of files\n",
    "                path = os.path.join(root, file)\n",
    "                # print(path)\n",
    "                dir_list.append(path)\n",
    "                # extractImages(path,'./data/train/real',frame_rate=15000)\n",
    "    count = extract_multiple_videos(dir_list,f'{out_dir}',img_class,frame_rate=frame_rate, resize=resize)\n",
    "    print(f'TOTAL FRAMES/IMAGES FORMED: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_vids_path = '/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/Revisiting-Pixel-Wise-Supervision-for-Face-Anti-Spoofing/replayattack/train_files/train/real/'\n",
    "train_spoof_fixed_vids_path = '/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/Revisiting-Pixel-Wise-Supervision-for-Face-Anti-Spoofing/replayattack/train_files/train/attack/fixed/'\n",
    "train_spoof_hand_vids_path = '/home/pineapple45/ANMOL/BTP/pixel-wise-supervision/Revisiting-Pixel-Wise-Supervision-for-Face-Anti-Spoofing/replayattack/train_files/train/attack/hand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_imgs_path = './replay-images/train/real/'\n",
    "train_spoof_fixed_imgs_path = './replay-images/train/spoof/fixed/'\n",
    "train_spoof_hand_imgs_path = './replay-images/train/spoof/hand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_real = {\"in_dir\": train_real_vids_path,\"out_dir\":train_real_imgs_path}\n",
    "train_dir_attack_fixed = {\"in_dir\":train_spoof_fixed_vids_path, 'out_dir':train_spoof_fixed_imgs_path}\n",
    "train_dir_attack_hand = {\"in_dir\":train_spoof_hand_vids_path, 'out_dir':train_spoof_hand_imgs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 22490\n"
     ]
    }
   ],
   "source": [
    "start(train_dir_real['in_dir'],train_dir_real['out_dir'],img_class=\"real\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 35466\n"
     ]
    }
   ],
   "source": [
    "start(train_dir_attack_fixed['in_dir'],train_dir_attack_fixed['out_dir'],img_class=\"attack_fixed\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 33749\n"
     ]
    }
   ],
   "source": [
    "start(train_dir_attack_hand['in_dir'],train_dir_attack_hand['out_dir'],img_class=\"attack_hand\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHANGE DIRECTORY STRUCTURE BY PLACING IMAGES PERSON WISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_wise_dataset_train_path = './dataset/train/images/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_list(path):\n",
    "    dir_list = []\n",
    "    for root, dirs, files in os.walk(f'{path}'):\n",
    "        # select file name\n",
    "        for file in files:\n",
    "            # check the extension of files\n",
    "            if file.endswith('.png'):\n",
    "                # print whole path of files\n",
    "                path = os.path.join(root, file)\n",
    "                # print(path)\n",
    "                dir_list.append(path)\n",
    "    return dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22490\n",
      "35466\n",
      "33749\n"
     ]
    }
   ],
   "source": [
    "img_path_list_train_real = get_dir_list(train_real_imgs_path)\n",
    "img_path_list_train_spoof_fixed = get_dir_list(train_spoof_fixed_imgs_path)\n",
    "img_path_list_train_spoof_hand = get_dir_list(train_spoof_hand_imgs_path)\n",
    "print(len(img_path_list_train_real)) # ./replay-images/train/real/\n",
    "print(len(img_path_list_train_spoof_fixed)) # ./replay-images/train/spoof/fixed\n",
    "print(len(img_path_list_train_spoof_hand)) # ./replay-images/train/spoof/hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./replay-images/train/real/client105_18228_real.png'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list_train_real[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_objects(path_list):\n",
    "    clients = {}\n",
    "    for file in path_list:\n",
    "        path_parts = file.split('/')\n",
    "        for part in path_parts:\n",
    "            if 'client' in part:\n",
    "                file_name_split = part.split('_')\n",
    "                client_key = file_name_split[0]\n",
    "                if client_key in clients.keys():\n",
    "                    clients[client_key].append(file)\n",
    "                else:\n",
    "                    clients[client_key] = [file]\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_client_objects =  get_client_objects(img_path_list_train_real)\n",
    "spoof_fixed_client_objects = get_client_objects(img_path_list_train_spoof_fixed)\n",
    "spoof_hand_client_objects = get_client_objects(img_path_list_train_spoof_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n",
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n",
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(real_client_objects.keys()))\n",
    "print(sorted(spoof_fixed_client_objects.keys()))\n",
    "print(sorted(spoof_hand_client_objects.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_wise_dir_list = get_dir_list(person_wise_dataset_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataGeneration.ipynb                              \u001b[0m\u001b[01;34mreplay-dummy-person-wise\u001b[0m/\r\n",
      " \u001b[01;34mdataset\u001b[0m/                                          \u001b[01;34mreplay-images\u001b[0m/\r\n",
      " haarcascade_frontalface_default.xml               \u001b[01;35mtest_img.png\u001b[0m\r\n",
      "'PIxel Wise Supervision - Siamese-Network.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE list.txt AND APPEND FORMATED PATHS OF IMAGES TO IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/list.txt', 'w') as f:\n",
    "    for path in person_wise_dir_list:\n",
    "        if '/dataset/train/images/' in path:\n",
    "            s = path.split('/dataset/train/images/')\n",
    "            p = s[1]\n",
    "            f.write(\"%s\\n\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client_key in sorted(real_client_objects.keys()):\n",
    "    if os.path.isdir(person_wise_dataset_train_path+client_key):\n",
    "        shutil.rmtree(person_wise_dataset_train_path+client_key)\n",
    "    single_client_path = person_wise_dataset_train_path+client_key\n",
    "    os.mkdir(single_client_path)\n",
    "    \n",
    "    single_client_path_real = single_client_path + '/real'\n",
    "    single_client_path_spoof = single_client_path + '/spoof'\n",
    "    os.mkdir(single_client_path_real)\n",
    "    os.mkdir(single_client_path_spoof)\n",
    "    for raw_client_image_path in real_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_real)\n",
    "    for raw_client_image_path in spoof_fixed_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_spoof)\n",
    "    for raw_client_image_path in spoof_hand_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_spoof)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pixel-wise-super]",
   "language": "python",
   "name": "conda-env-pixel-wise-super-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
